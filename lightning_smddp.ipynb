{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "behind-singapore",
   "metadata": {},
   "source": [
    "# Distributed data parallel minGPT training with PyTorch Lightning and SMDataParallel\n",
    "\n",
    "\n",
    "## Background\n",
    "SMDataParallel is a new capability in Amazon SageMaker to train deep learning models faster and cheaper. SMDataParallel is a distributed data parallel training framework for PyTorch. \n",
    "\n",
    "This notebook example shows how to use SMDataParallel with PyTorch Lightning in SageMaker.\n",
    "\n",
    "For more information:\n",
    "1. [PyTorch in SageMaker](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html)\n",
    "2. [SMDataParallel PyTorch API Specification](https://sagemaker.readthedocs.io/en/stable/api/training/smd_data_parallel_pytorch.html)\n",
    "3. [Getting started with SMDataParallel on SageMaker](https://sagemaker.readthedocs.io/en/stable/api/training/smd_data_parallel.html)\n",
    "\n",
    "**NOTE:** This example requires SageMaker Python SDK v2.X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "structured-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install sagemaker --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "persistent-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-values",
   "metadata": {},
   "source": [
    "## Model training with SMDataParallel\n",
    "\n",
    "### Training script\n",
    "\n",
    "The training script provides the code you need for distributed data parallel (DDP) training using SMDataParallel. The training script is very similar to a PyTorch Lightning training script you might run outside of SageMaker, but modified to run with SMDataParallel by passing the flag `accelerator=\"ddp_sm\"` to Trainer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "private-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize minGPT/benchmark.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-farmer",
   "metadata": {},
   "source": [
    "### Estimator function options\n",
    "\n",
    "In the following code block, you can update the estimator function to use a different instance type, instance count, and distrubtion strategy. You're also passing in the training script you reviewed in the previous cell.\n",
    "\n",
    "**Instance types**\n",
    "\n",
    "SMDataParallel supports model training on SageMaker with the following instance types only:\n",
    "1. ml.p3.16xlarge\n",
    "1. ml.p3dn.24xlarge [Recommended]\n",
    "1. ml.p4d.24xlarge [Recommended]\n",
    "\n",
    "**Instance count**\n",
    "\n",
    "To get the best performance and the most out of SMDataParallel, you should use at least 2 instances, but you can also use 1 for testing this example.\n",
    "\n",
    "**Distribution strategy**\n",
    "\n",
    "Note that to use DDP mode, you update the the `distribution` strategy, and set it to use `smdistributed dataparallel`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-motion",
   "metadata": {},
   "source": [
    "Pass the filename of the training script as the `entry_point` parameter and specify the directory name in `source_dir` argument. You can also include a `requirements.txt` file in the same directory as your training script to install other dependencies at runtime. That's where we add the Pytorch Lightning dependency.\n",
    "\n",
    "```\n",
    "code\n",
    "   |--training.py\n",
    "   |--requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"git+https://github.com/kaushikb11/pytorch-lightning.git@smddp\" > ./minGPT/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "radical-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point = \"benchmark.py\"\n",
    "source_dir = \"minGPT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-arnold",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(base_job_name='lightning-benchmarks',\n",
    "                        source_dir=source_dir,\n",
    "                        entry_point=entry_point,\n",
    "                        role=role,\n",
    "                        framework_version='1.6.0',\n",
    "                        py_version='py36',\n",
    "                        # For training with multinode distributed training, set this count. Example: 2\n",
    "                        instance_count=1,\n",
    "                        # For training with p3dn instance use - ml.p3dn.24xlarge, with p4dn instance use - ml.p4d.24xlarge\n",
    "                        instance_type= 'ml.p3.16xlarge',\n",
    "                        sagemaker_session=sagemaker_session,\n",
    "                        # Training using SMDataParallel Distributed Training Framework\n",
    "                        # Comment this when not training with smddp\n",
    "                        distribution={'smdistributed':{\n",
    "                                            'dataparallel':{\n",
    "                                                    'enabled': True\n",
    "                                                 }\n",
    "                                          }\n",
    "                                      },\n",
    "                        debugger_hook_config=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}